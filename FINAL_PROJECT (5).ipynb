{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Programming 2\n",
    "\n",
    "# Final Project \n",
    "(BD-2005: Moldir Kumarbek, Aiym Yermakhan, Baizhigitova Maryam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks:\n",
    "### Task 1 - Classification with prepared dataset (75% of mark)\n",
    "### Task 2 - Clustering with any dataset (25% of mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking scheme \n",
    "For Final:\n",
    "1. Data and task presentation - 10%\n",
    "2. Data Preprocessing - 20%\n",
    "3. Model (variety, complexity, tunning) - 20%\n",
    "4. Imbalance (approaching this issue) - 20%\n",
    "5. Code quality - 10%\n",
    "6. Results and Defence - 20%\n",
    "\n",
    "*Note: add comments and description of the approaches that you use, for example, for resolving the problem of imbalanced data. Write descriptions of techniques that you apply, and you should understand them as well.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "Мы постоянно работаем над улучшением качества своих продуктов и услуг для роста абонентской базы и минимизации оттока. В своей работе мы используем персональный подход к абонентам.\n",
    "Для снижения оттока компания использует разные каналы коммуникации с клиентами. Каждое предложение должно быть адресовано определенной целевой группе. В этом задании вам предстоит по имеющимся данным попытаться определить абонентов, которые уйдут в отток.\n",
    "\n",
    "**Что имеем**\n",
    "\n",
    "Анонимизированные данные об абонентах: язык обслуживания абонента, тарифный план, информация об объёмах потребления различных услуг оператора и другие.\n",
    "В файле data.csv содержится информация для построения модели.\n",
    "Формат строк: 3 категориальных признака (C1, C2, C3), 23 числовых признака (N1, …, N23) и целевая переменная — TARGET.\n",
    "\n",
    "**Что делать**\n",
    "\n",
    "Описать этапы построения модели, построить модель, оценить ее и рассказать бизнесу как ее применять, то есть нужна бизнес-интерпретация. \n",
    "\n",
    "*Note: this is how the task was originally structured, you can use it as a guidance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>...</th>\n",
       "      <th>N15</th>\n",
       "      <th>N16</th>\n",
       "      <th>N17</th>\n",
       "      <th>N18</th>\n",
       "      <th>N19</th>\n",
       "      <th>N20</th>\n",
       "      <th>N21</th>\n",
       "      <th>N22</th>\n",
       "      <th>N23</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3139363536333839</td>\n",
       "      <td>323531</td>\n",
       "      <td>33</td>\n",
       "      <td>83.74</td>\n",
       "      <td>3172.92</td>\n",
       "      <td>181.48</td>\n",
       "      <td>24.83</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3437333830323633</td>\n",
       "      <td>343835</td>\n",
       "      <td>31</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1273.88</td>\n",
       "      <td>92.11</td>\n",
       "      <td>211.78</td>\n",
       "      <td>28.98</td>\n",
       "      <td>5.75</td>\n",
       "      <td>13.85</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3134323931353339</td>\n",
       "      <td>323531</td>\n",
       "      <td>33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.95</td>\n",
       "      <td>763.19</td>\n",
       "      <td>48.13</td>\n",
       "      <td>77.22</td>\n",
       "      <td>9.33</td>\n",
       "      <td>4.90</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3431333831343031</td>\n",
       "      <td>343433</td>\n",
       "      <td>31</td>\n",
       "      <td>117.49</td>\n",
       "      <td>529.19</td>\n",
       "      <td>1506.40</td>\n",
       "      <td>127.67</td>\n",
       "      <td>49.30</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>56</td>\n",
       "      <td>148</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3233343933313234</td>\n",
       "      <td>343835</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.24</td>\n",
       "      <td>3493.18</td>\n",
       "      <td>389.98</td>\n",
       "      <td>72.78</td>\n",
       "      <td>16.72</td>\n",
       "      <td>4.28</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C1      C2  C3      N1       N2       N3      N4     N5  \\\n",
       "0  3139363536333839  323531  33   83.74  3172.92   181.48   24.83   9.60   \n",
       "1  3437333830323633  343835  31    1.46  1273.88    92.11  211.78  28.98   \n",
       "2  3134323931353339  323531  33    0.00    31.95   763.19   48.13  77.22   \n",
       "3  3431333831343031  343433  31  117.49   529.19  1506.40  127.67  49.30   \n",
       "4  3233343933313234  343835  31    0.00    38.24  3493.18  389.98  72.78   \n",
       "\n",
       "      N6     N7  ...  N15  N16  N17  N18  N19  N20  N21  N22  N23  TARGET  \n",
       "0   0.00   0.00  ...    7    0    0   36    7   36    7    0    0       0  \n",
       "1   5.75  13.85  ...   18    5    6   52   12   57   18    0    0       0  \n",
       "2   9.33   4.90  ...   24   18    6   46   18   64   24    0    0       0  \n",
       "3   6.25   0.20  ...   57    4    1  142   56  148   57    0    0       0  \n",
       "4  16.72   4.28  ...   28   17    5   69   23   86   28    0    0       0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('task1.csv', sep=';', decimal=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514009, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514009 entries, 0 to 514008\n",
      "Data columns (total 27 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   C1      514009 non-null  int64  \n",
      " 1   C2      514009 non-null  int64  \n",
      " 2   C3      514009 non-null  int64  \n",
      " 3   N1      514009 non-null  float64\n",
      " 4   N2      514009 non-null  float64\n",
      " 5   N3      514009 non-null  float64\n",
      " 6   N4      514009 non-null  float64\n",
      " 7   N5      514009 non-null  float64\n",
      " 8   N6      514009 non-null  float64\n",
      " 9   N7      514009 non-null  float64\n",
      " 10  N8      514009 non-null  float64\n",
      " 11  N9      514009 non-null  float64\n",
      " 12  N10     514009 non-null  float64\n",
      " 13  N11     514009 non-null  float64\n",
      " 14  N12     514009 non-null  float64\n",
      " 15  N13     514009 non-null  float64\n",
      " 16  N14     514009 non-null  int64  \n",
      " 17  N15     514009 non-null  int64  \n",
      " 18  N16     514009 non-null  int64  \n",
      " 19  N17     514009 non-null  int64  \n",
      " 20  N18     514009 non-null  int64  \n",
      " 21  N19     514009 non-null  int64  \n",
      " 22  N20     514009 non-null  int64  \n",
      " 23  N21     514009 non-null  int64  \n",
      " 24  N22     514009 non-null  int64  \n",
      " 25  N23     514009 non-null  int64  \n",
      " 26  TARGET  514009 non-null  int64  \n",
      "dtypes: float64(13), int64(14)\n",
      "memory usage: 105.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>...</th>\n",
       "      <th>N15</th>\n",
       "      <th>N16</th>\n",
       "      <th>N17</th>\n",
       "      <th>N18</th>\n",
       "      <th>N19</th>\n",
       "      <th>N20</th>\n",
       "      <th>N21</th>\n",
       "      <th>N22</th>\n",
       "      <th>N23</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3139363536333839</td>\n",
       "      <td>323531</td>\n",
       "      <td>33</td>\n",
       "      <td>83.74</td>\n",
       "      <td>3172.92</td>\n",
       "      <td>181.48</td>\n",
       "      <td>24.83</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3437333830323633</td>\n",
       "      <td>343835</td>\n",
       "      <td>31</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1273.88</td>\n",
       "      <td>92.11</td>\n",
       "      <td>211.78</td>\n",
       "      <td>28.98</td>\n",
       "      <td>5.75</td>\n",
       "      <td>13.85</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3134323931353339</td>\n",
       "      <td>323531</td>\n",
       "      <td>33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.95</td>\n",
       "      <td>763.19</td>\n",
       "      <td>48.13</td>\n",
       "      <td>77.22</td>\n",
       "      <td>9.33</td>\n",
       "      <td>4.90</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3431333831343031</td>\n",
       "      <td>343433</td>\n",
       "      <td>31</td>\n",
       "      <td>117.49</td>\n",
       "      <td>529.19</td>\n",
       "      <td>1506.40</td>\n",
       "      <td>127.67</td>\n",
       "      <td>49.30</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>56</td>\n",
       "      <td>148</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3233343933313234</td>\n",
       "      <td>343835</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.24</td>\n",
       "      <td>3493.18</td>\n",
       "      <td>389.98</td>\n",
       "      <td>72.78</td>\n",
       "      <td>16.72</td>\n",
       "      <td>4.28</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514000</th>\n",
       "      <td>3530363934383336</td>\n",
       "      <td>313339</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514003</th>\n",
       "      <td>3533363433373937</td>\n",
       "      <td>313339</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514005</th>\n",
       "      <td>3335363533383731</td>\n",
       "      <td>313339</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514006</th>\n",
       "      <td>3535343831313531</td>\n",
       "      <td>343637</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514008</th>\n",
       "      <td>3334313139353932</td>\n",
       "      <td>343038</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377326 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      C1      C2  C3      N1       N2       N3      N4     N5  \\\n",
       "0       3139363536333839  323531  33   83.74  3172.92   181.48   24.83   9.60   \n",
       "1       3437333830323633  343835  31    1.46  1273.88    92.11  211.78  28.98   \n",
       "2       3134323931353339  323531  33    0.00    31.95   763.19   48.13  77.22   \n",
       "3       3431333831343031  343433  31  117.49   529.19  1506.40  127.67  49.30   \n",
       "4       3233343933313234  343835  31    0.00    38.24  3493.18  389.98  72.78   \n",
       "...                  ...     ...  ..     ...      ...      ...     ...    ...   \n",
       "514000  3530363934383336  313339  31    0.00     0.00     0.00    0.00   1.68   \n",
       "514003  3533363433373937  313339  31    0.00     0.00     0.00    0.00   0.00   \n",
       "514005  3335363533383731  313339  31    0.00     0.00     0.00    0.00   0.12   \n",
       "514006  3535343831313531  343637  31    0.00     0.00     0.00    0.00   1.27   \n",
       "514008  3334313139353932  343038  31    0.00     0.00     0.00    0.00   0.00   \n",
       "\n",
       "           N6     N7  ...  N15  N16  N17  N18  N19  N20  N21  N22  N23  TARGET  \n",
       "0        0.00   0.00  ...    7    0    0   36    7   36    7    0    0       0  \n",
       "1        5.75  13.85  ...   18    5    6   52   12   57   18    0    0       0  \n",
       "2        9.33   4.90  ...   24   18    6   46   18   64   24    0    0       0  \n",
       "3        6.25   0.20  ...   57    4    1  142   56  148   57    0    0       0  \n",
       "4       16.72   4.28  ...   28   17    5   69   23   86   28    0    0       0  \n",
       "...       ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...  \n",
       "514000   0.00   0.00  ...    1    0    0    0    1    0    1    0    0       0  \n",
       "514003   0.00   0.00  ...    0    0    0    0    0    0    0    0    0       0  \n",
       "514005   0.00   0.12  ...    1    0    1    0    0    0    1    0    0       0  \n",
       "514006   0.00   1.27  ...    1    0    1    0    0    0    1    0    0       0  \n",
       "514008   0.00   0.00  ...    0    0    0    0    0    0    0    0    0       0  \n",
       "\n",
       "[377326 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    488665\n",
       "1     25344\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df['TARGET'].value_counts()[1]/len(df),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliluabk/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TARGET', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "sns.countplot(df['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "X = df.drop(columns='TARGET')\n",
    "y = df['TARGET']\n",
    "X = MinMaxScaler().fit(X).transform(X) # Normalization\n",
    "X = StandardScaler().fit(X).transform(X) # Standartization\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression before resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95064298 0.95066244 0.95060407 0.95070135 0.95068189 0.95064298\n",
      " 0.95066244 0.95066244 0.95068189 0.95070039]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print(cross_val_score(LogisticRegression(max_iter=10000), X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4755099182107532\n",
      "Recall: 0.4999918172965985\n",
      "F-score: 0.4874436600055842\n",
      "Accuracy: 0.9510050349019089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print('Precision:',prf[0])\n",
    "print('Recall:',prf[1])\n",
    "print('F-score:',prf[2])\n",
    "print('Accuracy:',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df0 = df[(df['TARGET']==0)]\n",
    "df1 = df[(df['TARGET']==1)]\n",
    "df = pd.concat([resample(df1,replace=True,n_samples=df1.shape[0]),\n",
    "                resample(df0,replace=True,n_samples=df1.shape[0])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267472</td>\n",
       "      <td>0.319579</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.411283</td>\n",
       "      <td>-0.485524</td>\n",
       "      <td>-0.462419</td>\n",
       "      <td>-0.456795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587243</td>\n",
       "      <td>-0.688878</td>\n",
       "      <td>-0.449081</td>\n",
       "      <td>-0.509353</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.652365</td>\n",
       "      <td>-0.586465</td>\n",
       "      <td>-0.688413</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.404733</td>\n",
       "      <td>-0.292385</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.414580</td>\n",
       "      <td>-0.485524</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.456795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606357</td>\n",
       "      <td>-0.688878</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.509353</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.652365</td>\n",
       "      <td>-0.605589</td>\n",
       "      <td>-0.688413</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404789</td>\n",
       "      <td>0.313539</td>\n",
       "      <td>1.744487</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324375</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.414580</td>\n",
       "      <td>-0.206148</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.235522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606357</td>\n",
       "      <td>-0.551381</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.318574</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.563198</td>\n",
       "      <td>-0.605589</td>\n",
       "      <td>-0.550861</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271661</td>\n",
       "      <td>0.317735</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.414580</td>\n",
       "      <td>-0.485524</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.456795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606357</td>\n",
       "      <td>-0.688878</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.509353</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.652365</td>\n",
       "      <td>-0.605589</td>\n",
       "      <td>-0.688413</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.408978</td>\n",
       "      <td>-0.292385</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430919</td>\n",
       "      <td>-0.414580</td>\n",
       "      <td>-0.304433</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.456795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606357</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.509353</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.161946</td>\n",
       "      <td>-0.605589</td>\n",
       "      <td>-0.310144</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50683</th>\n",
       "      <td>0.131555</td>\n",
       "      <td>0.309627</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.414580</td>\n",
       "      <td>-0.480222</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.422221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606357</td>\n",
       "      <td>-0.654503</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.413963</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.652365</td>\n",
       "      <td>-0.605589</td>\n",
       "      <td>-0.654025</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50684</th>\n",
       "      <td>-0.015558</td>\n",
       "      <td>0.117044</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>0.403741</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.225129</td>\n",
       "      <td>-0.378757</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.325414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043516</td>\n",
       "      <td>0.204850</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.223185</td>\n",
       "      <td>0.215947</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>0.044638</td>\n",
       "      <td>0.205676</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50685</th>\n",
       "      <td>0.130167</td>\n",
       "      <td>0.309607</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>-0.414580</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>-0.495005</td>\n",
       "      <td>-0.456795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606357</td>\n",
       "      <td>-0.413884</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>-0.509353</td>\n",
       "      <td>-0.555150</td>\n",
       "      <td>-0.295697</td>\n",
       "      <td>-0.605589</td>\n",
       "      <td>-0.413308</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50686</th>\n",
       "      <td>0.267471</td>\n",
       "      <td>0.317735</td>\n",
       "      <td>-0.573265</td>\n",
       "      <td>-0.130592</td>\n",
       "      <td>0.817490</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>0.448872</td>\n",
       "      <td>-0.465381</td>\n",
       "      <td>-0.198874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215541</td>\n",
       "      <td>0.342346</td>\n",
       "      <td>-0.449081</td>\n",
       "      <td>-0.127795</td>\n",
       "      <td>0.397381</td>\n",
       "      <td>0.506807</td>\n",
       "      <td>0.216757</td>\n",
       "      <td>0.343228</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50687</th>\n",
       "      <td>-0.155663</td>\n",
       "      <td>-0.280385</td>\n",
       "      <td>1.744487</td>\n",
       "      <td>-0.138757</td>\n",
       "      <td>-0.324440</td>\n",
       "      <td>-0.430931</td>\n",
       "      <td>0.341726</td>\n",
       "      <td>0.202577</td>\n",
       "      <td>-0.353997</td>\n",
       "      <td>-0.439508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>0.101727</td>\n",
       "      <td>-0.294329</td>\n",
       "      <td>-0.413963</td>\n",
       "      <td>0.306664</td>\n",
       "      <td>0.328473</td>\n",
       "      <td>0.178508</td>\n",
       "      <td>0.102512</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.053491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50688 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.267472  0.319579 -0.573265 -0.138757 -0.324440 -0.430931 -0.411283   \n",
       "1      0.404733 -0.292385 -0.573265 -0.138757 -0.324440 -0.430931 -0.414580   \n",
       "2      0.404789  0.313539  1.744487 -0.138757 -0.324375 -0.430931 -0.414580   \n",
       "3      0.271661  0.317735 -0.573265 -0.138757 -0.324440 -0.430931 -0.414580   \n",
       "4      0.408978 -0.292385 -0.573265 -0.138757 -0.324440 -0.430919 -0.414580   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "50683  0.131555  0.309627 -0.573265 -0.138757 -0.324440 -0.430931 -0.414580   \n",
       "50684 -0.015558  0.117044 -0.573265 -0.138757  0.403741 -0.430931 -0.225129   \n",
       "50685  0.130167  0.309607 -0.573265 -0.138757 -0.324440 -0.430931 -0.414580   \n",
       "50686  0.267471  0.317735 -0.573265 -0.130592  0.817490 -0.430931  0.152395   \n",
       "50687 -0.155663 -0.280385  1.744487 -0.138757 -0.324440 -0.430931  0.341726   \n",
       "\n",
       "             7         8         9   ...        16        17        18  \\\n",
       "0     -0.485524 -0.462419 -0.456795  ... -0.587243 -0.688878 -0.449081   \n",
       "1     -0.485524 -0.495005 -0.456795  ... -0.606357 -0.688878 -0.526457   \n",
       "2     -0.206148 -0.495005 -0.235522  ... -0.606357 -0.551381 -0.526457   \n",
       "3     -0.485524 -0.495005 -0.456795  ... -0.606357 -0.688878 -0.526457   \n",
       "4     -0.304433 -0.495005 -0.456795  ... -0.606357 -0.310762 -0.526457   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "50683 -0.480222 -0.495005 -0.422221  ... -0.606357 -0.654503 -0.526457   \n",
       "50684 -0.378757 -0.495005 -0.325414  ...  0.043516  0.204850 -0.526457   \n",
       "50685  0.381971 -0.495005 -0.456795  ... -0.606357 -0.413884 -0.526457   \n",
       "50686  0.448872 -0.465381 -0.198874  ...  0.215541  0.342346 -0.449081   \n",
       "50687  0.202577 -0.353997 -0.439508  ...  0.177313  0.101727 -0.294329   \n",
       "\n",
       "             19        20        21        22        23        24        25  \n",
       "0     -0.509353 -0.555150 -0.652365 -0.586465 -0.688413 -0.083818 -0.053491  \n",
       "1     -0.509353 -0.555150 -0.652365 -0.605589 -0.688413 -0.083818 -0.053491  \n",
       "2     -0.318574 -0.555150 -0.563198 -0.605589 -0.550861 -0.083818 -0.053491  \n",
       "3     -0.509353 -0.555150 -0.652365 -0.605589 -0.688413 -0.083818 -0.053491  \n",
       "4     -0.509353 -0.555150 -0.161946 -0.605589 -0.310144 -0.083818 -0.053491  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "50683 -0.413963 -0.555150 -0.652365 -0.605589 -0.654025 -0.083818 -0.053491  \n",
       "50684 -0.223185  0.215947  0.373056  0.044638  0.205676 -0.083818 -0.053491  \n",
       "50685 -0.509353 -0.555150 -0.295697 -0.605589 -0.413308 -0.083818 -0.053491  \n",
       "50686 -0.127795  0.397381  0.506807  0.216757  0.343228 -0.083818 -0.053491  \n",
       "50687 -0.413963  0.306664  0.328473  0.178508  0.102512 -0.083818 -0.053491  \n",
       "\n",
       "[50688 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='TARGET')\n",
    "y = df['TARGET']\n",
    "X = MinMaxScaler().fit(X).transform(X) # Normalization\n",
    "X = StandardScaler().fit(X).transform(X) # Standartization\n",
    "X = pd.DataFrame(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25344\n",
       "1    25344\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliluabk/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TARGET', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "sns.countplot(df['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75498126 0.74866838 0.74156638 0.74807654 0.74906293 0.7431446\n",
      " 0.75734859 0.74136911 0.74782952 0.74921073]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(LogisticRegression(max_iter=10000), X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7561712199992434\n",
      "Recall: 0.7482841906401703\n",
      "F-score: 0.7460763844275986\n",
      "Accuracy: 0.7479482323232324\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print('Precision:',prf[0])\n",
    "print('Recall:',prf[1])\n",
    "print('F-score:',prf[2])\n",
    "print('Accuracy:',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# parameter grid\n",
    "parameters = {\n",
    "    'penalty' : ['l1','l2'], \n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "clf = GridSearchCV(logreg,                    # model\n",
    "                   param_grid = parameters,   # hyperparameters\n",
    "                   scoring='accuracy',        # metric for scoring\n",
    "                   cv=10)                     # number of folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy : 0.7482636978751265\n",
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Accuracy :\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7481849747474747\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 1000.0, \n",
    "                            penalty = 'l2', \n",
    "                            solver = 'lbfgs')\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier (Stochastic gradient descent)\n",
    "Supports multi-class classification by combining multiple binary classifiers in a “one versus all” (OVA) scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7533228253180935\n",
      "Recall: 0.7433558720137743\n",
      "F-score: 0.7405200117352462\n",
      "Accuracy: 0.7429766414141414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print('Precision:',prf[0])\n",
    "print('Recall:',prf[1])\n",
    "print('F-score:',prf[2])\n",
    "print('Accuracy:',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7716749643384304\n",
      "Recall: 0.7715830284334122\n",
      "F-score: 0.7715307200244598\n",
      "Accuracy: 0.7715435606060606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print('Precision:',prf[0])\n",
    "print('Recall:',prf[1])\n",
    "print('F-score:',prf[2])\n",
    "print('Accuracy:',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "GB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8003300572631\n",
      "Recall: 0.8002388382715164\n",
      "F-score: 0.8002449601417382\n",
      "Accuracy: 0.7715435606060606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test)\n",
    "prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print('Precision:',prf[0])\n",
    "print('Recall:',prf[1])\n",
    "print('F-score:',prf[2])\n",
    "print('Accuracy:',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8039524171993346\n",
      "Recall: 0.8024574335796446\n",
      "F-score: 0.8021016438643916\n",
      "Accuracy: 0.8023200757575758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = clf = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "prf = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "print('Precision:',prf[0])\n",
    "print('Recall:',prf[1])\n",
    "print('F-score:',prf[2])\n",
    "print('Accuracy:',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>75.72 %</td>\n",
       "      <td>74.72 %</td>\n",
       "      <td>74.59 %</td>\n",
       "      <td>74.89 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>75.56 %</td>\n",
       "      <td>74.16 %</td>\n",
       "      <td>73.95 %</td>\n",
       "      <td>74.37 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>77.56 %</td>\n",
       "      <td>77.52 %</td>\n",
       "      <td>77.53 %</td>\n",
       "      <td>77.55 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>80.17 %</td>\n",
       "      <td>80.18 %</td>\n",
       "      <td>80.16 %</td>\n",
       "      <td>77.55 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>80.95 %</td>\n",
       "      <td>80.66 %</td>\n",
       "      <td>80.67 %</td>\n",
       "      <td>80.74 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Precision   Recall  F-score Accuracy\n",
       "LogisticRegression           75.72 %  74.72 %  74.59 %  74.89 %\n",
       "SGDClassifier                75.56 %  74.16 %  73.95 %  74.37 %\n",
       "KNeighborsClassifier         77.56 %  77.52 %  77.53 %  77.55 %\n",
       "GradientBoostingClassifier   80.17 %  80.18 %  80.16 %  77.55 %\n",
       "DecisionTreeClassifier       80.95 %  80.66 %  80.67 %  80.74 %"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dict()\n",
    "data['LogisticRegression'] = {\n",
    "    'Precision': 0.7571555009867676,\n",
    "    'Recall': 0.7471506650672132,\n",
    "    'F-score': 0.7459167269491838,\n",
    "    'Accuracy': 0.748895202020202\n",
    "}\n",
    "data['SGDClassifier'] = {\n",
    "    'Precision': 0.7555612962484572,\n",
    "    'Recall': 0.7416052799010007,\n",
    "    'F-score': 0.7395239055375001,\n",
    "    'Accuracy': 0.7436868686868687\n",
    "}\n",
    "data['KNeighborsClassifier'] = {\n",
    "    'Precision': 0.7756195101263659,\n",
    "    'Recall': 0.7751750775898667,\n",
    "    'F-score': 0.7752686937060835,\n",
    "    'Accuracy': 0.7754892676767676\n",
    "}\n",
    "data['GradientBoostingClassifier'] = {\n",
    "    'Precision': 0.8016864041237328,\n",
    "    'Recall': 0.8017754113401074,\n",
    "    'F-score': 0.8016030828581653,\n",
    "    'Accuracy': 0.7754892676767676\n",
    "}\n",
    "data['DecisionTreeClassifier'] = {\n",
    "    'Precision': 0.8094628368588814,\n",
    "    'Recall': 0.8065658104925675,\n",
    "    'F-score': 0.8067096495972397,\n",
    "    'Accuracy': 0.8073705808080808\n",
    "}\n",
    "round(pd.DataFrame(data).T * 100, 2).astype(str) + \" %\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we can say that the use of data classification and processing models and observing the results that were made during data analysis, we were able to achieve useful ideas. They also described the stages of building a model, built a model, appreciated it. And these data were used for a random classifier of forest, hyperparameter settings, logistics regression, classifier of solutions, KNN, imbalance to obtain the desired results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
